{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/o0jayzaza0o/pythonaipidterm/blob/main/Image_classification_Hand_on.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay2MSEhwlwn-"
      },
      "source": [
        "# Image Classification with FastAI\n"
      ],
      "id": "Ay2MSEhwlwn-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "740DogWIlwoA"
      },
      "outputs": [],
      "source": [
        "from fastai.vision.all import *\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ],
      "id": "740DogWIlwoA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/datasets/vencerlanz09/sea-animals-image-dataste"
      ],
      "metadata": {
        "id": "TRJ233HgovOl"
      },
      "id": "TRJ233HgovOl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gF-Rf_NolwoB"
      },
      "source": [
        "## Prepare Data\n",
        "- ใช้ `ImageDataLoaders.from_folder()`\n",
        "- โฟลเดอร์ข้อมูลควรมีโครงสร้างแบบ:\n",
        "```\n",
        "data/\n",
        "  train/\n",
        "    class1/\n",
        "    class2/\n",
        "```\n"
      ],
      "id": "gF-Rf_NolwoB"
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaXEN7_qWZ2A",
        "outputId": "eafc5c01-8cf7-4d46-a621-b70344862fa8"
      },
      "id": "oaXEN7_qWZ2A",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/gpiosenka/musical-instruments-image-classification?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 204M/204M [00:01<00:00, 173MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/gpiosenka/musical-instruments-image-classification/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "download_path = \"⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚\"\n",
        "\n",
        "destination_path = \"⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚\"\n",
        "\n",
        "if os.path.exists(destination_path):\n",
        "    print(f\"Removing existing directory: {destination_path}\")\n",
        "    shutil.rmtree(destination_path)\n",
        "\n",
        "shutil.move(download_path, destination_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sgadfno7WeCF",
        "outputId": "a2cb2b84-6b88-4626-c01e-2e2cf84dd370"
      },
      "id": "sgadfno7WeCF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/musical-instruments-dataset'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "dls = ImageDataLoaders.from_folder(\n",
        "    path,                             # ตำแหน่งของโฟลเดอร์ข้อมูลรูปภาพ แยกตามคลาสย่อยในโฟลเดอร์ย่อย\n",
        "    valid_pct=0.2,                    # แบ่งข้อมูล 20% สำหรับ validation set เพื่อใช้ประเมินผลระหว่างการเทรน\n",
        "    seed=42,                          # ตั้งค่า seed เพื่อให้การแบ่งข้อมูล train/valid เหมือนเดิมทุกครั้งที่รัน\n",
        "    item_tfms=Resize(224),            # ปรับขนาดภาพทั้งหมดให้มีขนาด 224x224 เท่ากันก่อนเข้าสู่ batch\n",
        "    batch_tfms=aug_transforms(\n",
        "      do_flip = True,                 # พลิกภาพแบบแนวนอน (Horizontal flip) แบบสุ่ม\n",
        "      flip_vert = True,               # พลิกภาพแบบแนวตั้ง (Vertical flip) แบบสุ่ม\n",
        "      max_rotate = 90,                # หมุนภาพแบบสุ่มสูงสุด 90 องศา\n",
        "      min_zoom = 1,                   # กำหนดการซูมแบบสุ่ม โดยไม่เล็กกว่าขนาดจริง (ขั้นต่ำ = 1 เท่า)\n",
        "      max_zoom = 4.1,                 # กำหนดการซูมสูงสุดเป็น 4.1 เท่า (ขยายได้มาก)\n",
        "      max_lighting = 0.2,             # ปรับแสง/คอนทราสต์ของภาพแบบสุ่มในระดับไม่เกิน 20%\n",
        "      max_warp = 0.2,                 # บิดยืดรูปทรงของภาพแบบ perspective warp ได้ไม่เกิน 20%\n",
        "      p_affine = 0.75,                # โอกาส 75% ที่จะทำการแปลงแบบ affine (หมุน, ซูม, บิด)\n",
        "      p_lighting = 0.75,              # โอกาส 75% ที่จะเปลี่ยนแสง/คอนทราสต์ของภาพ\n",
        "      mode = \"bilinear\",              # โหมดการปรับภาพ (interpolation) ใช้แบบ bilinear (นุ่มนวล)\n",
        "      pad_mode = \"reflection\",        # ถ้าต้อง padding จะใช้ค่าจากการสะท้อนขอบภาพ\n",
        "    ),\n",
        "    bs=32                             # จำนวนภาพต่อหนึ่ง batch ขณะ training\n",
        ")\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "sPmYqhuAgf47"
      },
      "id": "sPmYqhuAgf47"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4p5daqHlwoC"
      },
      "outputs": [],
      "source": [
        "\n",
        "path = Path('⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚')\n",
        "dls = ImageDataLoaders.from_folder(\n",
        "    path,\n",
        "    item_tfms=Resize(224),\n",
        "    batch_tfms=aug_transforms(),\n",
        "    bs=32\n",
        ")"
      ],
      "id": "I4p5daqHlwoC"
    },
    {
      "cell_type": "code",
      "source": [
        "dls.valid.show_batch(max_n=10,nrows=2)"
      ],
      "metadata": {
        "id": "NdB23JKeYCSB"
      },
      "id": "NdB23JKeYCSB",
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "dls.train.show_batch(max_n=20, nrows=2)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "2J-lTUb7slUC"
      },
      "id": "2J-lTUb7slUC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dls.vocab"
      ],
      "metadata": {
        "id": "D0K6eXBjX7OF"
      },
      "id": "D0K6eXBjX7OF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSMgrPx4lwoC"
      },
      "source": [
        "## Define Learner\n",
        "- ใช้ `vision_learner()` เพื่อโหลดโมเดลและเมตริก\n",
        "- โมเดลตัวอย่าง: `resnet18`, `resnet34`, `resnet50` 'dir(models)'"
      ],
      "id": "qSMgrPx4lwoC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfzBIGIslwoC"
      },
      "outputs": [],
      "source": [
        "learn = vision_learner(dls, ⬚⬚⬚⬚⬚⬚⬚⬚, metrics=accuracy)"
      ],
      "id": "SfzBIGIslwoC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cx4Xr1oFlwoE"
      },
      "source": [
        "## Summary"
      ],
      "id": "cx4Xr1oFlwoE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kD6qsBcZlwoE"
      },
      "outputs": [],
      "source": [
        "learn.model"
      ],
      "id": "kD6qsBcZlwoE"
    },
    {
      "cell_type": "code",
      "source": [
        "learn.summary()"
      ],
      "metadata": {
        "id": "eHd5SJsOnlYg"
      },
      "id": "eHd5SJsOnlYg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Suggest Learning rate"
      ],
      "metadata": {
        "id": "KAPtZ5GMmPRP"
      },
      "id": "KAPtZ5GMmPRP"
    },
    {
      "cell_type": "code",
      "source": [
        "learn.lr_find()"
      ],
      "metadata": {
        "id": "usg4WzV1mZH6"
      },
      "id": "usg4WzV1mZH6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkBCr-k8lwoE"
      },
      "source": [
        "## Train the Model"
      ],
      "id": "LkBCr-k8lwoE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "Pi-l4Od6lwoF",
        "outputId": "7bb3ae2a-1725-4e82-e30c-ca22e3008889"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.618943</td>\n",
              "      <td>0.239469</td>\n",
              "      <td>0.940000</td>\n",
              "      <td>00:51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.549597</td>\n",
              "      <td>0.063143</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>00:51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.282000</td>\n",
              "      <td>0.029306</td>\n",
              "      <td>0.993333</td>\n",
              "      <td>00:51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.154992</td>\n",
              "      <td>0.012147</td>\n",
              "      <td>0.993333</td>\n",
              "      <td>00:51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.103235</td>\n",
              "      <td>0.009421</td>\n",
              "      <td>0.993333</td>\n",
              "      <td>00:51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.066864</td>\n",
              "      <td>0.004037</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>00:51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.055318</td>\n",
              "      <td>0.003111</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>00:51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.043562</td>\n",
              "      <td>0.002193</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>00:52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.035351</td>\n",
              "      <td>0.005218</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>00:54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.028701</td>\n",
              "      <td>0.003239</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>00:53</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "learn.fine_tune(epochs= ⬚⬚⬚, base_lr= ⬚⬚⬚⬚⬚⬚ ,freeze_epochs=0 )"
      ],
      "id": "Pi-l4Od6lwoF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw7281SWlwoF"
      },
      "source": [
        "## Interpret Results"
      ],
      "id": "Iw7281SWlwoF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLkw_X80lwoF"
      },
      "outputs": [],
      "source": [
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_confusion_matrix()"
      ],
      "id": "GLkw_X80lwoF"
    },
    {
      "cell_type": "code",
      "source": [
        "interp.plot_top_losses(5, nrows=1)"
      ],
      "metadata": {
        "id": "YxOUsmmyasMP"
      },
      "id": "YxOUsmmyasMP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.show_results(max_n=15,shuffle=True)"
      ],
      "metadata": {
        "id": "RYLuPpdrnyE5"
      },
      "id": "RYLuPpdrnyE5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "cyupKKB0jGQV"
      },
      "id": "cyupKKB0jGQV"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,15)) # Adjusted figure size for more subplots\n",
        "base_test_path = '⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚' # Base path to your test data\n",
        "\n",
        "c = 0\n",
        "max_images_to_show = 100 # You can adjust this number\n",
        "subplot_rows = 10 # Adjust based on max_images_to_show\n",
        "subplot_cols = 10 # Adjust based on max_images_to_show\n",
        "\n",
        "# Iterate through each class directory in the test data\n",
        "for class_name in os.listdir(base_test_path):\n",
        "    class_path = os.path.join(base_test_path, class_name)\n",
        "    if os.path.isdir(class_path): # Ensure it's a directory\n",
        "        # Iterate through images in the current class directory\n",
        "        for image_name in os.listdir(class_path)[:max_images_to_show // len(os.listdir(base_test_path))]: # Limit images per class\n",
        "            if c < max_images_to_show: # Stop after showing max_images_to_show\n",
        "                plt.subplot(subplot_rows, subplot_cols, c + 1) # Use c+1 for subplot index\n",
        "\n",
        "                image_path = os.path.join(class_path, image_name)\n",
        "                try:\n",
        "                    img = Image.open(image_path).resize((200, 200))\n",
        "\n",
        "                    pred_class, pred_idx, outputs = learn.predict(img)\n",
        "\n",
        "                    # Set title color based on correct/incorrect prediction\n",
        "                    if pred_class == class_name:\n",
        "                        plt.title(pred_class, color='green') # Correct prediction in green\n",
        "                    else:\n",
        "                        plt.title(f'Pred: {pred_class}\\nActual: {class_name}', color='red', weight='bold') # Incorrect prediction in bold red\n",
        "\n",
        "                    plt.imshow(img) # Removed cmap='gray' for color images\n",
        "                    plt.axis('off')\n",
        "                    c += 1\n",
        "                except Exception as e:\n",
        "                    print(f\"Could not process image {image_path}: {e}\")\n",
        "\n",
        "plt.tight_layout() # Adjust subplot parameters for a tight layout\n",
        "plt.show() # Show the plot"
      ],
      "metadata": {
        "id": "IxHNhZ5Iakkg"
      },
      "id": "IxHNhZ5Iakkg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i16DYBKlwoG"
      },
      "source": [
        "## Export Model"
      ],
      "id": "9i16DYBKlwoG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNOWVyo1lwoG"
      },
      "outputs": [],
      "source": [
        "learn.export('⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚⬚')"
      ],
      "id": "xNOWVyo1lwoG"
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOeqG1rXbCwx",
        "outputId": "b2dd1063-9bcb-4f87-ce3f-edccf3474085"
      },
      "id": "sOeqG1rXbCwx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "musical-instruments-dataset  sample_data\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}